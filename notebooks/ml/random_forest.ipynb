{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import plotly.offline as py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"flights\").getOrCreate()\n",
    "import json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType, TimestampType\n",
    "with open(\"../../util/schema.json\",\"r\") as f:\n",
    "    schema = StructType.fromJson(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"../../data.nosync/cleaned/cleaned_flights.csv\",schema=schema, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column 'label' that is 1 if the flight is delayed and 0 if it is not\n",
    "df = df.withColumn(\"label\", when(df[\"ArrDelay\"] > 0, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    " 'Quarter',\n",
    " 'Month',\n",
    " 'DayofMonth',\n",
    " 'DayOfWeek',\n",
    " 'Reporting_Airline',\n",
    " 'Origin',\n",
    " 'Dest',\n",
    " #'DepDelay',\n",
    " 'CRSDepTime',\n",
    " 'CRSArrTime',\n",
    " 'CRSElapsedTime',\n",
    " 'AirTime',\n",
    " 'Distance',\n",
    " 'ORIGIN_STATE',\n",
    " 'DEST_STATE',\n",
    " 'label'\n",
    " ]\n",
    "\n",
    "\n",
    "# mantain only the features in features list\n",
    "df = df.select(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(False,0.07,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "categoricalCols = [field for (field, dataType) in df.dtypes\n",
    "if dataType == \"string\"]\n",
    "\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "oheOutputCols = [x + \"OHE\" for x in categoricalCols]\n",
    "\n",
    "stringIndexer = StringIndexer(inputCols=categoricalCols,\n",
    "                                outputCols=indexOutputCols,\n",
    "                                handleInvalid=\"skip\")\n",
    "oheEncoder = OneHotEncoder(inputCols=indexOutputCols,\n",
    "                            outputCols=oheOutputCols)\n",
    "\n",
    "numericCols = [field for (field, dataType) in df.dtypes\n",
    "                    if ((dataType == \"double\" or dataType == \"int\" ) & (field != \"label\"))]\n",
    "\n",
    "assemblerInputs = oheOutputCols + numericCols\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=assemblerInputs,\n",
    "                        outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline\n",
    "pipeline = Pipeline(stages=[stringIndexer, oheEncoder, vecAssembler])\n",
    "\n",
    "# fit the pipeline to the data\n",
    "pipelineModel = pipeline.fit(df)\n",
    "\n",
    "# transform the data\n",
    "df_proc = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features and label columns\n",
    "df_proc = df_proc.select(\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 5 rows\n",
    "df_proc.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows with label 1\n",
    "df_proc.filter(df_proc.label == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows with label 0\n",
    "df_proc.filter(df_proc.label == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 2501251/3745488\n",
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "train, test = df_proc.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_1 = train.filter(train.label == 1)\n",
    "\n",
    "\n",
    "train_0 = train.filter(train.label == 0).sample(False, sample_rate, seed=42)\n",
    "\n",
    "\n",
    "# merge the two datasets\n",
    "train = train_1.union(train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows with label 1\n",
    "train.filter(train.label == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows with label 0\n",
    "train.filter(train.label == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a grid search to find the best hyperparameters\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", seed=42)\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [2, 4, 6]) \\\n",
    "    .addGrid(rf.maxBins, [20, 60]) \\\n",
    "    .addGrid(rf.numTrees, [20, 60]) \\\n",
    "    .build()\n",
    "\n",
    "# use the grid with 8-fold cross validation\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                            estimatorParamMaps=paramGrid,\n",
    "                            evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\"),\n",
    "                            numFolds=5)\n",
    "\n",
    "# fit the model\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# get the best model\n",
    "bestModel = cvModel.bestModel\n",
    "\n",
    "# get the best hyperparameters\n",
    "bestModel.extractParamMap()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â create the model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=30,maxDepth=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "predictions = model.transform(train)\n",
    "\n",
    "# evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "\n",
    "# print the accuracy\n",
    "print(\"Accuracy = %g \" % accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Error = 0.419311 \n",
    "Accuracy = 0.580689 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the predictions and the true label\n",
    "predictions.select(\"prediction\", \"label\").show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
